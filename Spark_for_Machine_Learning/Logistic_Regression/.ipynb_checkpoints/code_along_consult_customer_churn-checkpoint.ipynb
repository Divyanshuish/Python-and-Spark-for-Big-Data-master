{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"customer_churn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"customer_churn.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|\n",
      "|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|\n",
      "|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|\n",
      "|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|    1|\n",
      "|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|    1|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a column 'days_since_Onboard' until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      " |-- days_since_Onboard: integer (nullable = true)\n",
      "\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+------------------+\n",
      "|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|days_since_Onboard|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+------------------+\n",
      "|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|              1554|\n",
      "|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|              1571|\n",
      "|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|               520|\n",
      "|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|    1|              1319|\n",
      "|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|    1|               682|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add a column 'days_since_Onboard' until now\n",
    "\n",
    "from pyspark.sql.functions import datediff, current_date\n",
    "data = data.withColumn(\"days_since_Onboard\",\n",
    "                       datediff(current_date(),data['Onboard_date']).alias(\"days_since_Onboard\"))\n",
    "\n",
    "data.printSchema()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only columns with numeric data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for dataPoint in data.dtypes:\n",
    "    if ((dataPoint[1]=='double') or (dataPoint[1]=='int')):\n",
    "        cols.append(dataPoint[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------+-----+---------+-----+------------------+\n",
      "| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|days_since_Onboard|\n",
      "+----+--------------+---------------+-----+---------+-----+------------------+\n",
      "|42.0|       11066.8|              0| 7.22|      8.0|    1|              1554|\n",
      "|41.0|      11916.22|              0|  6.5|     11.0|    1|              1571|\n",
      "|38.0|      12884.75|              0| 6.67|     12.0|    1|               520|\n",
      "|42.0|       8010.76|              0| 6.71|     10.0|    1|              1319|\n",
      "|37.0|       9191.58|              0| 5.56|      9.0|    1|               682|\n",
      "+----+--------------+---------------+-----+---------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_model = data.select(cols)\n",
    "data_model.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total customers: 900\n",
      "Customers with no account manager: 467\n",
      "Customers with account manager: 433\n"
     ]
    }
   ],
   "source": [
    "print('Total customers:', data_model.count())\n",
    "print('Customers with no account manager:', data_model.filter(data_model['Account_Manager']==0).count())\n",
    "print('Customers with account manager:', data_model.filter(data_model['Account_Manager']==1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|corr(Churn, Account_Manager)|\n",
      "+----------------------------+\n",
      "|         0.07061077173214911|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "data.select(corr(\"Churn\",\"Account_Manager\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some correlation between 'Churn' and 'Account_Manager' but it is small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal is to predict whether a customer will churn without an account manager assigned\n",
    "## Since account manager is randomly assigned, let's not put it in the model and select only customer with no account manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer with no account manager to use in the model: 467\n",
      "+----+--------------+---------------+-----+---------+-----+------------------+\n",
      "| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|days_since_Onboard|\n",
      "+----+--------------+---------------+-----+---------+-----+------------------+\n",
      "|42.0|       11066.8|              0| 7.22|      8.0|    1|              1554|\n",
      "|41.0|      11916.22|              0|  6.5|     11.0|    1|              1571|\n",
      "|38.0|      12884.75|              0| 6.67|     12.0|    1|               520|\n",
      "|42.0|       8010.76|              0| 6.71|     10.0|    1|              1319|\n",
      "|37.0|       9191.58|              0| 5.56|      9.0|    1|               682|\n",
      "+----+--------------+---------------+-----+---------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_model = data_model.filter(data_model['Account_Manager']==0)\n",
    "print('Customer with no account manager to use in the model:', data_model.count())\n",
    "\n",
    "data_model.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----+---------+-----+------------------+\n",
      "| Age|Total_Purchase|Years|Num_Sites|Churn|days_since_Onboard|\n",
      "+----+--------------+-----+---------+-----+------------------+\n",
      "|42.0|       11066.8| 7.22|      8.0|    1|              1554|\n",
      "|41.0|      11916.22|  6.5|     11.0|    1|              1571|\n",
      "|38.0|      12884.75| 6.67|     12.0|    1|               520|\n",
      "|42.0|       8010.76| 6.71|     10.0|    1|              1319|\n",
      "|37.0|       9191.58| 5.56|      9.0|    1|               682|\n",
      "+----+--------------+-----+---------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_model = data_model.drop('Account_Manager')\n",
    "data_model.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Total_Purchase', 'Years', 'Num_Sites', 'days_since_Onboard']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecCols = data_model.columns\n",
    "vecCols.remove('Churn')\n",
    "vecCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|Churn|            features|\n",
      "+-----+--------------------+\n",
      "|    1|[42.0,11066.8,7.2...|\n",
      "|    1|[41.0,11916.22,6....|\n",
      "|    1|[38.0,12884.75,6....|\n",
      "|    1|[42.0,8010.76,6.7...|\n",
      "|    1|[37.0,9191.58,5.5...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=vecCols,outputCol='features')\n",
    "data_feed = assembler.transform(data_model).select('Churn','features')\n",
    "data_feed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data_feed.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "logReg = LogisticRegression(featuresCol='features',labelCol='Churn')\n",
    "logReg_trained = logReg.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|Churn|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|[25.0,9672.03,5.4...|[6.10755038453111...|[0.99777894708088...|       0.0|\n",
      "|  0.0|[28.0,11204.23,3....|[2.57296956546668...|[0.92910155613014...|       0.0|\n",
      "|  0.0|[28.0,11245.38,6....|[3.94298207931874...|[0.98097852714545...|       0.0|\n",
      "|  0.0|[29.0,9378.24,4.9...|[4.96194947726990...|[0.99304937965899...|       0.0|\n",
      "|  0.0|[29.0,9617.59,5.4...|[4.91974328684861...|[0.99275191344503...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logReg_trained.summary.predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = logReg_trained.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|Churn|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|[26.0,8939.61,4.5...|[7.44290306906282...|[0.99941475996603...|       0.0|\n",
      "|    0|[28.0,8670.98,3.9...|[8.70498946309901...|[0.99983427076339...|       0.0|\n",
      "|    0|[30.0,6744.87,5.1...|[3.89790318797779...|[0.98011887717878...|       0.0|\n",
      "|    0|[30.0,8874.83,5.5...|[4.34816101815511...|[0.98723449543560...|       0.0|\n",
      "|    0|[30.0,12788.37,4....|[3.37787740922448...|[0.96700595009313...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use .evaluate to get more complete info of evaluation on the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_2 = logReg_trained.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|Churn|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|[26.0,8939.61,4.5...|[7.44290306906282...|[0.99941475996603...|       0.0|\n",
      "|    0|[28.0,8670.98,3.9...|[8.70498946309901...|[0.99983427076339...|       0.0|\n",
      "|    0|[30.0,6744.87,5.1...|[3.89790318797779...|[0.98011887717878...|       0.0|\n",
      "|    0|[30.0,8874.83,5.5...|[4.34816101815511...|[0.98723449543560...|       0.0|\n",
      "|    0|[30.0,12788.37,4....|[3.37787740922448...|[0.96700595009313...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results_2.predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary'>\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "<class 'pyspark.ml.classification.BinaryLogisticRegressionSummary'>\n"
     ]
    }
   ],
   "source": [
    "print(type(logReg_trained.summary))\n",
    "print(type(test_results))\n",
    "print(type(test_results_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9125631313131312"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Area under ROC:\")\n",
    "bi_eval = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='Churn', metricName='areaUnderROC')\n",
    "bi_eval.evaluate(test_results_2.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easier way to get Area under ROC:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9125631313131312"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Easier way to get Area under ROC:\")\n",
    "test_results_2.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8846153846153846"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy:\")\n",
    "multi_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol='Churn',metricName='accuracy')\n",
    "multi_eval.evaluate(test_results_2.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on new_customer.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train the model with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_trained_new = logReg.fit(data_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|Churn|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  1.0|[42.0,11066.8,7.2...|[2.23652653000433...|[0.90348198797847...|       0.0|\n",
      "|  1.0|[41.0,11916.22,6....|[-0.5986565768745...|[0.35465110792153...|       1.0|\n",
      "|  1.0|[38.0,12884.75,6....|[-1.7123122602926...|[0.15286404544922...|       1.0|\n",
      "|  1.0|[42.0,8010.76,6.7...|[0.38729397854017...|[0.59563111035065...|       0.0|\n",
      "|  1.0|[37.0,9191.58,5.5...|[2.73066510395521...|[0.93881205455145...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logReg_trained_new.summary.predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare new customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cus = spark.read.csv(\"new_customers.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_cus.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+\n",
      "|         Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|         Company|\n",
      "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+\n",
      "| Andrew Mccall|37.0|       9935.53|              1| 7.71|      8.0|2011-08-29 18:37:54|38612 Johnny Stra...|        King Ltd|\n",
      "|Michele Wright|23.0|       7526.94|              1| 9.28|     15.0|2013-07-22 18:19:54|21083 Nicole Junc...|   Cannon-Benson|\n",
      "|  Jeremy Chang|65.0|         100.0|              1|  1.0|     15.0|2006-12-11 07:48:13|085 Austin Views ...|Barron-Robertson|\n",
      "|Megan Ferguson|32.0|        6487.5|              0|  9.4|     14.0|2016-10-28 05:32:13|922 Wright Branch...|   Sexton-Golden|\n",
      "|  Taylor Young|32.0|      13147.71|              1| 10.0|      8.0|2012-03-20 00:36:46|Unit 0789 Box 073...|        Wood LLC|\n",
      "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_cus.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cus = new_cus.withColumn(\"days_since_Onboard\",\n",
    "                       datediff(current_date(),new_cus['Onboard_date']).alias(\"days_since_Onboard\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+------------------+\n",
      "|         Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|         Company|days_since_Onboard|\n",
      "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+------------------+\n",
      "| Andrew Mccall|37.0|       9935.53|              1| 7.71|      8.0|2011-08-29 18:37:54|38612 Johnny Stra...|        King Ltd|              2286|\n",
      "|Michele Wright|23.0|       7526.94|              1| 9.28|     15.0|2013-07-22 18:19:54|21083 Nicole Junc...|   Cannon-Benson|              1593|\n",
      "|  Jeremy Chang|65.0|         100.0|              1|  1.0|     15.0|2006-12-11 07:48:13|085 Austin Views ...|Barron-Robertson|              4008|\n",
      "|Megan Ferguson|32.0|        6487.5|              0|  9.4|     14.0|2016-10-28 05:32:13|922 Wright Branch...|   Sexton-Golden|               399|\n",
      "|  Taylor Young|32.0|      13147.71|              1| 10.0|      8.0|2012-03-20 00:36:46|Unit 0789 Box 073...|        Wood LLC|              2082|\n",
      "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_cus.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "new_cus_cols = deepcopy(cols)\n",
    "new_cus_cols.remove('Churn')\n",
    "new_cus_cols.remove('Account_Manager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+--------------+-----+---------+------------------+\n",
      "|         Names| Age|Total_Purchase|Years|Num_Sites|days_since_Onboard|\n",
      "+--------------+----+--------------+-----+---------+------------------+\n",
      "| Andrew Mccall|37.0|       9935.53| 7.71|      8.0|              2286|\n",
      "|Michele Wright|23.0|       7526.94| 9.28|     15.0|              1593|\n",
      "|  Jeremy Chang|65.0|         100.0|  1.0|     15.0|              4008|\n",
      "|Megan Ferguson|32.0|        6487.5|  9.4|     14.0|               399|\n",
      "|  Taylor Young|32.0|      13147.71| 10.0|      8.0|              2082|\n",
      "+--------------+----+--------------+-----+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add 'Names' column to keep track of which company will churn\n",
    "new_cus_data = new_cus.select(['Names'] + new_cus_cols)\n",
    "new_cus_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|         Names|            features|\n",
      "+--------------+--------------------+\n",
      "| Andrew Mccall|[37.0,9935.53,7.7...|\n",
      "|Michele Wright|[23.0,7526.94,9.2...|\n",
      "|  Jeremy Chang|[65.0,100.0,1.0,1...|\n",
      "|Megan Ferguson|[32.0,6487.5,9.4,...|\n",
      "|  Taylor Young|[32.0,13147.71,10...|\n",
      "| Jessica Drake|[22.0,8445.26,3.4...|\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_cus_assembler = VectorAssembler(inputCols=new_cus_cols,outputCol='features')\n",
    "new_cus_feed = new_cus_assembler.transform(new_cus_data).select('Names','features')\n",
    "new_cus_feed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cus_pred = logReg_trained_new.transform(new_cus_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+--------------------+----------+\n",
      "|         Names|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------+--------------------+--------------------+--------------------+----------+\n",
      "| Andrew Mccall|[37.0,9935.53,7.7...|[2.64005513006689...|[0.93339539185674...|       0.0|\n",
      "|Michele Wright|[23.0,7526.94,9.2...|[-4.7916586352367...|[0.00823038017150...|       1.0|\n",
      "|  Jeremy Chang|[65.0,100.0,1.0,1...|[-3.3301432046926...|[0.03455145299582...|       1.0|\n",
      "|Megan Ferguson|[32.0,6487.5,9.4,...|[-4.9249814260398...|[0.00721049237351...|       1.0|\n",
      "|  Taylor Young|[32.0,13147.71,10...|[1.50674699488292...|[0.81857861120005...|       0.0|\n",
      "| Jessica Drake|[22.0,8445.26,3.4...|[0.51843421908199...|[0.62678156153494...|       0.0|\n",
      "+--------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_cus_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to re-consider whether to drop not to drop 'Account_Manager' in train data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
