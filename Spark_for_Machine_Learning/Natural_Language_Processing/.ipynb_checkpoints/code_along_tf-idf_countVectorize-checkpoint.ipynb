{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('tools_2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, 'Hi I heard about Spark'),\n",
    "    (0.0, 'I wish Java could use case classes'),\n",
    "    (1.0, 'Logistic regression models are neat')\n",
    "], ['label', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            sentence|\n",
      "+-----+--------------------+\n",
      "|  0.0|Hi I heard about ...|\n",
      "|  0.0|I wish Java could...|\n",
      "|  1.0|Logistic regressi...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentenceData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First tokenize the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='sentence', outputCol='words')\n",
    "count_tokens = udf(lambda words_sep: len(words_sep), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data = tokenizer.transform(sentenceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+------+\n",
      "|label|            sentence|               words|tokens|\n",
      "+-----+--------------------+--------------------+------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|     5|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|     7|\n",
      "|  1.0|Logistic regressi...|[logistic, regres...|     5|\n",
      "+-----+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_data.withColumn('tokens', count_tokens(words_data['words'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_tf = HashingTF(inputCol='words', outputCol='rawFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|            sentence|               words|         rawFeatures|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|(262144,[24417,49...|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|(262144,[20719,24...|\n",
      "|  1.0|Logistic regressi...|[logistic, regres...|(262144,[13671,91...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurized_data = hashing_tf.transform(words_data)\n",
    "featurized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol='rawFeatures', outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_model = idf.fit(featurized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_data = idf_model.transform(featurized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|            sentence|               words|         rawFeatures|            features|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|(262144,[24417,49...|(262144,[24417,49...|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|(262144,[20719,24...|(262144,[20719,24...|\n",
      "|  1.0|Logistic regressi...|[logistic, regres...|(262144,[13671,91...|(262144,[13671,91...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, sentence='Hi I heard about Spark', words=['hi', 'i', 'heard', 'about', 'spark'], rawFeatures=SparseVector(262144, {24417: 1.0, 49304: 1.0, 73197: 1.0, 91137: 1.0, 234657: 1.0}), features=SparseVector(262144, {24417: 0.2877, 49304: 0.6931, 73197: 0.6931, 91137: 0.6931, 234657: 0.6931}))]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (0, 'a b b c'.split(' ')),\n",
    "    (1, 'a b b b c a d'.split(' '))\n",
    "], ['id', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+\n",
      "|id |words                |\n",
      "+---+---------------------+\n",
      "|0  |[a, b, b, c]         |\n",
      "|1  |[a, b, b, b, c, a, d]|\n",
      "+---+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVec = CountVectorizer(inputCol='words', outputCol='features', vocabSize=3, minDF=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = countVec.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+-------------------------+\n",
      "|id |words                |features                 |\n",
      "+---+---------------------+-------------------------+\n",
      "|0  |[a, b, b, c]         |(3,[0,1,2],[2.0,1.0,1.0])|\n",
      "|1  |[a, b, b, b, c, a, d]|(3,[0,1,2],[3.0,2.0,1.0])|\n",
      "+---+---------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
